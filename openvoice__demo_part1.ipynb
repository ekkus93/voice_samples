{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OpenVoice v1\n",
        "Based on https://github.com/myshell-ai/OpenVoice/blob/main/demo_part1.ipynb"
      ],
      "metadata": {
        "id": "DJtm_xaKWPSA"
      },
      "id": "DJtm_xaKWPSA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download voice samples repo"
      ],
      "metadata": {
        "id": "rdTjPXrIaYrU"
      },
      "id": "rdTjPXrIaYrU"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && wget https://github.com/ekkus93/voice_samples/archive/refs/heads/master.zip && unzip master.zip && rm master.zip"
      ],
      "metadata": {
        "id": "t1A50kN0aa0C"
      },
      "id": "t1A50kN0aa0C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Install OpenVoice"
      ],
      "metadata": {
        "id": "v6kwHUgdZucz"
      },
      "id": "v6kwHUgdZucz"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && wget https://github.com/myshell-ai/OpenVoice/archive/refs/heads/main.zip && unzip main.zip && rm main.zip"
      ],
      "metadata": {
        "id": "6dGi6ocWUPSs"
      },
      "id": "6dGi6ocWUPSs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/OpenVoice-main && pip install ."
      ],
      "metadata": {
        "id": "GSCshsZEU-nC"
      },
      "id": "GSCshsZEU-nC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster_whisper"
      ],
      "metadata": {
        "id": "O8E-dv4NYVbU"
      },
      "id": "O8E-dv4NYVbU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fix numpy version"
      ],
      "metadata": {
        "id": "1YwbgLOyZ06O"
      },
      "id": "1YwbgLOyZ06O"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "id": "eJGnOXiWXLs-"
      },
      "id": "eJGnOXiWXLs-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b6ee1ede",
      "metadata": {
        "id": "b6ee1ede"
      },
      "source": [
        "## Voice Style Control Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7f043ee",
      "metadata": {
        "id": "b7f043ee"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from openvoice import se_extractor\n",
        "from openvoice.api import BaseSpeakerTTS, ToneColorConverter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be106fc",
      "metadata": {
        "id": "7be106fc"
      },
      "outputs": [],
      "source": [
        "# prompt: Prompt user for a Huggingface access token and save it as an environment variable\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# Prompt user for Hugging Face access token\n",
        "hf_token = getpass.getpass('Enter your Hugging Face access token: ')\n",
        "\n",
        "# Save the token as an environment variable\n",
        "os.environ['HF_TOKEN'] = hf_token"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download models"
      ],
      "metadata": {
        "id": "bLcmsap_YjMN"
      },
      "id": "bLcmsap_YjMN"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/OpenVoice-main && wget https://myshell-public-repo-host.s3.amazonaws.com/openvoice/checkpoints_1226.zip && unzip checkpoints_1226.zip"
      ],
      "metadata": {
        "id": "HoIwRv4aYmRi"
      },
      "id": "HoIwRv4aYmRi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/OpenVoice-main && wget https://myshell-public-repo-host.s3.amazonaws.com/openvoice/checkpoints_v2_0417.zip && unzip checkpoints_v2_0417.zip"
      ],
      "metadata": {
        "id": "uJzmyW9VYqrE"
      },
      "id": "uJzmyW9VYqrE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "15116b59",
      "metadata": {
        "id": "15116b59"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: change python current path to /content/OpenVoice-main\n",
        "\n",
        "os.chdir(\"/content/OpenVoice-main\")\n",
        "!pwd"
      ],
      "metadata": {
        "id": "mm2-HN9vX8Zu"
      },
      "id": "mm2-HN9vX8Zu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aacad912",
      "metadata": {
        "id": "aacad912"
      },
      "outputs": [],
      "source": [
        "ckpt_base = 'checkpoints/base_speakers/EN'\n",
        "ckpt_converter = 'checkpoints/converter'\n",
        "device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "output_dir = 'outputs'\n",
        "\n",
        "base_speaker_tts = BaseSpeakerTTS(f'{ckpt_base}/config.json', device=device)\n",
        "base_speaker_tts.load_ckpt(f'{ckpt_base}/checkpoint.pth')\n",
        "\n",
        "tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)\n",
        "tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f67740c",
      "metadata": {
        "id": "7f67740c"
      },
      "source": [
        "### Obtain Tone Color Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8add279",
      "metadata": {
        "id": "f8add279"
      },
      "source": [
        "The `source_se` is the tone color embedding of the base speaker.\n",
        "It is an average of multiple sentences generated by the base speaker. We directly provide the result here but\n",
        "the readers feel free to extract `source_se` by themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ff6273",
      "metadata": {
        "id": "63ff6273"
      },
      "outputs": [],
      "source": [
        "source_se = torch.load(f'{ckpt_base}/en_default_se.pth').to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f71fcc3",
      "metadata": {
        "id": "4f71fcc3"
      },
      "source": [
        "The `reference_speaker.mp3` below points to the short audio clip of the reference whose voice we want to clone. We provide an example here. If you use your own reference speakers, please **make sure each speaker has a unique filename.** The `se_extractor` will save the `targeted_se` using the filename of the audio and **will not automatically overwrite.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option 1: Default reference speaker"
      ],
      "metadata": {
        "id": "qLnIESj3bQXy"
      },
      "id": "qLnIESj3bQXy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55105eae",
      "metadata": {
        "id": "55105eae"
      },
      "outputs": [],
      "source": [
        "reference_speaker = 'resources/example_reference.mp3' # This is the voice you want to clone\n",
        "target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, target_dir='processed', vad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option 2: Pick a voice from voice samples"
      ],
      "metadata": {
        "id": "nTEv5P-mbYuM"
      },
      "id": "nTEv5P-mbYuM"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "voice_samples_dir = \"/content/voice_samples-master/voice_samples\"\n",
        "voice_files = sorted([f for f in os.listdir(voice_samples_dir) if os.path.isfile(os.path.join(voice_samples_dir, f))])\n",
        "\n",
        "# Create the dropdown menu using ipywidgets\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=[\"None\"] + voice_files,\n",
        "    value=\"None\",\n",
        "    description='Select voice file:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "display(dropdown)"
      ],
      "metadata": {
        "id": "Ys29Nus_btLE"
      },
      "id": "Ys29Nus_btLE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference_speaker = f\"/content/voice_samples-master/voice_samples/{dropdown.value}\"\n",
        "print(f\"Selected voice file: {reference_speaker}\")\n",
        "target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, target_dir='processed', vad=True)"
      ],
      "metadata": {
        "id": "OMs2y61jb01L"
      },
      "id": "OMs2y61jb01L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(reference_speaker)"
      ],
      "metadata": {
        "id": "RArTnxYbfecK"
      },
      "id": "RArTnxYbfecK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option 3: Use your own voice"
      ],
      "metadata": {
        "id": "M7BwzYrycC6x"
      },
      "id": "M7BwzYrycC6x"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "from IPython.display import display, HTML, Javascript\n",
        "from base64 import b64decode\n",
        "\n",
        "sample_text = \"\"\"\n",
        "With the police helicopters thundering towards us,\n",
        "and Marla and all the support group people who couldn't save themselves,\n",
        "with all of them trying to save me, I had to pull the trigger.\n",
        "This was better than real life.\n",
        "\"\"\"\n",
        "print(sample_text)\n",
        "\n",
        "# Register the save function to receive audio data from JS\n",
        "def save_audio(data, filename=\"/content/myvoice.wav\"):\n",
        "    audio_data = b64decode(data)\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(audio_data)\n",
        "    print(f\"Audio saved as {filename}\")\n",
        "\n",
        "output.register_callback('notebook.save_audio', save_audio)\n",
        "\n",
        "# Display recording controls in Colab\n",
        "display(HTML('''\n",
        "  <div>\n",
        "    <button id=\"start-record\">Start Recording</button>\n",
        "    <button id=\"stop-record\" disabled>Stop Recording</button>\n",
        "  </div>\n",
        "'''))\n",
        "\n",
        "display(Javascript('''\n",
        "let mediaRecorder;\n",
        "let audioChunks;\n",
        "\n",
        "document.getElementById(\"start-record\").onclick = async () => {\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "  mediaRecorder = new MediaRecorder(stream);\n",
        "  audioChunks = [];\n",
        "\n",
        "  mediaRecorder.ondataavailable = event => {\n",
        "    if (event.data.size > 0) {\n",
        "      audioChunks.push(event.data);\n",
        "    }\n",
        "  };\n",
        "\n",
        "  mediaRecorder.onstop = async () => {\n",
        "    const audioBlob = new Blob(audioChunks);\n",
        "    const reader = new FileReader();\n",
        "    reader.readAsDataURL(audioBlob);\n",
        "    reader.onloadend = () => {\n",
        "      const base64data = reader.result.split(',')[1];\n",
        "      google.colab.kernel.invokeFunction('notebook.save_audio', [base64data], {});\n",
        "    };\n",
        "  };\n",
        "\n",
        "  mediaRecorder.start();\n",
        "  document.getElementById(\"start-record\").disabled = true;\n",
        "  document.getElementById(\"stop-record\").disabled = false;\n",
        "};\n",
        "\n",
        "document.getElementById(\"stop-record\").onclick = () => {\n",
        "  mediaRecorder.stop();\n",
        "  document.getElementById(\"start-record\").disabled = false;\n",
        "  document.getElementById(\"stop-record\").disabled = true;\n",
        "};\n",
        "'''))\n"
      ],
      "metadata": {
        "id": "n5Pd7EQEcJ6s"
      },
      "id": "n5Pd7EQEcJ6s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to proper wav format using ffmpeg\n",
        "!ffmpeg -y -i /content/myvoice.wav -acodec pcm_s16le -ar 44100 /content/myvoice_fixed.wav && mv /content/myvoice_fixed.wav /content/myvoice.wav"
      ],
      "metadata": {
        "id": "wv0lF0MFcR91"
      },
      "id": "wv0lF0MFcR91",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference_speaker = \"/content/myvoice.wav\"\n",
        "print(f\"Selected voice file: {reference_speaker}\")\n",
        "target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, target_dir='processed', vad=True)"
      ],
      "metadata": {
        "id": "LHABc7wJcgHX"
      },
      "id": "LHABc7wJcgHX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(reference_speaker)"
      ],
      "metadata": {
        "id": "o8PalAEVcVb1"
      },
      "id": "o8PalAEVcVb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a40284aa",
      "metadata": {
        "id": "a40284aa"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73dc1259",
      "metadata": {
        "id": "73dc1259"
      },
      "outputs": [],
      "source": [
        "save_path = f'{output_dir}/output_en_default.wav'\n",
        "\n",
        "# Run the base speaker tts\n",
        "text = \"This audio is generated by OpenVoice.\"\n",
        "src_path = f'{output_dir}/tmp.wav'\n",
        "base_speaker_tts.tts(text, src_path, speaker='default', language='English', speed=1.0)\n",
        "\n",
        "# Run the tone color converter\n",
        "encode_message = \"@MyShell\"\n",
        "tone_color_converter.convert(\n",
        "    audio_src_path=src_path,\n",
        "    src_se=source_se,\n",
        "    tgt_se=target_se,\n",
        "    output_path=save_path,\n",
        "    message=encode_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4c40a86",
      "metadata": {
        "id": "f4c40a86"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "print(save_path)\n",
        "\n",
        "# Path to your .wav file\n",
        "Audio(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e3ea28a",
      "metadata": {
        "id": "6e3ea28a"
      },
      "source": [
        "**Try with different styles and speed.** The style can be controlled by the `speaker` parameter in the `base_speaker_tts.tts` method. Available choices: friendly, cheerful, excited, sad, angry, terrified, shouting, whispering. Note that the tone color embedding need to be updated. The speed can be controlled by the `speed` parameter. Let's try whispering with speed 0.9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5abaf3",
      "metadata": {
        "id": "8b5abaf3"
      },
      "outputs": [],
      "source": [
        "ckpt_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd022d38",
      "metadata": {
        "id": "fd022d38"
      },
      "outputs": [],
      "source": [
        "source_se = torch.load(f'checkpoints/base_speakers/EN/en_style_se.pth').to(device)\n",
        "save_path = f'{output_dir}/output_whispering.wav'\n",
        "\n",
        "# Run the base speaker tts\n",
        "text = \"This audio is generated by OpenVoice.\"\n",
        "src_path = f'{output_dir}/tmp.wav'\n",
        "base_speaker_tts.tts(text, src_path, speaker='whispering', language='English', speed=0.9)\n",
        "\n",
        "# Run the tone color converter\n",
        "encode_message = \"@MyShell\"\n",
        "tone_color_converter.convert(\n",
        "    audio_src_path=src_path,\n",
        "    src_se=source_se,\n",
        "    tgt_se=target_se,\n",
        "    output_path=save_path,\n",
        "    message=encode_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c0f6b02",
      "metadata": {
        "id": "7c0f6b02"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "print(save_path)\n",
        "\n",
        "# Path to your .wav file\n",
        "Audio(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fcfc70b",
      "metadata": {
        "id": "5fcfc70b"
      },
      "source": [
        "**Try with different languages.** OpenVoice can achieve multi-lingual voice cloning by simply replace the base speaker. We provide an example with a Chinese base speaker here and we encourage the readers to try `demo_part2.ipynb` for a detailed demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71d1387",
      "metadata": {
        "id": "a71d1387"
      },
      "outputs": [],
      "source": [
        "\n",
        "ckpt_base = 'checkpoints/base_speakers/ZH'\n",
        "base_speaker_tts = BaseSpeakerTTS(f'{ckpt_base}/config.json', device=device)\n",
        "base_speaker_tts.load_ckpt(f'{ckpt_base}/checkpoint.pth')\n",
        "\n",
        "source_se = torch.load(f'{ckpt_base}/zh_default_se.pth').to(device)\n",
        "save_path = f'{output_dir}/output_chinese.wav'\n",
        "\n",
        "# Run the base speaker tts\n",
        "text = \"今天天气真好，我们一起出去吃饭吧。\"\n",
        "src_path = f'{output_dir}/tmp.wav'\n",
        "base_speaker_tts.tts(text, src_path, speaker='default', language='Chinese', speed=1.0)\n",
        "\n",
        "# Run the tone color converter\n",
        "encode_message = \"@MyShell\"\n",
        "tone_color_converter.convert(\n",
        "    audio_src_path=src_path,\n",
        "    src_se=source_se,\n",
        "    tgt_se=target_se,\n",
        "    output_path=save_path,\n",
        "    message=encode_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6233ecad",
      "metadata": {
        "id": "6233ecad"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "print(save_path)\n",
        "\n",
        "# Path to your .wav file\n",
        "Audio(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e513094",
      "metadata": {
        "id": "8e513094"
      },
      "source": [
        "**Tech for good.** For people who will deploy OpenVoice for public usage: We offer you the option to add watermark to avoid potential misuse. Please see the ToneColorConverter class. **MyShell reserves the ability to detect whether an audio is generated by OpenVoice**, no matter whether the watermark is added or not."
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "9d70c38e1c0b038dbdffdaa4f8bfa1f6767c43760905c87a9fbe7800d18c6c35"
    },
    "kernelspec": {
      "display_name": "openvoice",
      "language": "python",
      "name": "condaenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}