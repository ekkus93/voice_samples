{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OpenVoice v2\n",
        "Based on https://github.com/myshell-ai/OpenVoice/blob/main/demo_part3.ipynb"
      ],
      "metadata": {
        "id": "2X80S6xGCGfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download voice samples repo"
      ],
      "metadata": {
        "id": "-Lz2zkVXCcVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && wget https://github.com/ekkus93/voice_samples/archive/refs/heads/master.zip && unzip master.zip && rm master.zip"
      ],
      "metadata": {
        "id": "2gAlMaPrCkxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Install OpenVoice"
      ],
      "metadata": {
        "id": "2NLpdFB_Coio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && wget https://github.com/myshell-ai/OpenVoice/archive/refs/heads/main.zip && unzip main.zip && rm main.zip"
      ],
      "metadata": {
        "id": "PToEPtuQCpj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/OpenVoice-main && pip install ."
      ],
      "metadata": {
        "id": "mZRpzD_5Cv3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster_whisper"
      ],
      "metadata": {
        "id": "VwS-ikK8CzUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fix numpy version"
      ],
      "metadata": {
        "id": "uiMBhk3YC2_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "id": "TD_bXfOdC65i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/myshell-ai/MeloTTS.git"
      ],
      "metadata": {
        "id": "hjO9jn71H5lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-hub==0.23.5"
      ],
      "metadata": {
        "id": "gvVYx7WKMajk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Prompt user for a Huggingface access token and save it as an environment variable\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# Prompt user for Hugging Face access token\n",
        "hf_token = getpass.getpass('Enter your Hugging Face access token: ')\n",
        "\n",
        "# Save the token as an environment variable\n",
        "os.environ['HF_TOKEN'] = hf_token"
      ],
      "metadata": {
        "id": "qv4DjR74DM3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Voice Style Control Demo"
      ],
      "metadata": {
        "id": "5jBWgkTvDC0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from openvoice import se_extractor\n",
        "from openvoice.api import BaseSpeakerTTS, ToneColorConverter"
      ],
      "metadata": {
        "id": "HqNC_OGzDGXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download models"
      ],
      "metadata": {
        "id": "Lt1P6z8sDQgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/OpenVoice-main && wget https://myshell-public-repo-host.s3.amazonaws.com/openvoice/checkpoints_1226.zip && unzip -o checkpoints_1226.zip"
      ],
      "metadata": {
        "id": "oNnhuVvIDUn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/OpenVoice-main && wget https://myshell-public-repo-host.s3.amazonaws.com/openvoice/checkpoints_v2_0417.zip && unzip -o checkpoints_v2_0417.zip"
      ],
      "metadata": {
        "id": "RgYJDiFsDVe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization"
      ],
      "metadata": {
        "id": "1fKDtsMRDbP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"/content/OpenVoice-main\")\n",
        "!pwd"
      ],
      "metadata": {
        "id": "6tcz96S-DeD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_base = 'checkpoints/base_speakers/EN'\n",
        "ckpt_converter = 'checkpoints/converter'\n",
        "device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "output_dir = 'outputs'\n",
        "\n",
        "base_speaker_tts = BaseSpeakerTTS(f'{ckpt_base}/config.json', device=device)\n",
        "base_speaker_tts.load_ckpt(f'{ckpt_base}/checkpoint.pth')\n",
        "\n",
        "tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)\n",
        "tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UkSD1_cLDhFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oRNOtMSOCpxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvRn7bObBmrZ"
      },
      "source": [
        "## Multi-Accent and Multi-Lingual Voice Clone Demo with MeloTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkQAfMuhBmre"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from openvoice import se_extractor\n",
        "from openvoice.api import ToneColorConverter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1Fifd-VBmrk"
      },
      "source": [
        "### Initialization\n",
        "\n",
        "In this example, we will use the checkpoints from OpenVoiceV2. OpenVoiceV2 is trained with more aggressive augmentations and thus demonstrate better robustness in some cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXoE75cJBmrn"
      },
      "outputs": [],
      "source": [
        "ckpt_converter = 'checkpoints_v2/converter'\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "output_dir = 'outputs_v2'\n",
        "\n",
        "tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)\n",
        "tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYOR5J7LBmrp"
      },
      "source": [
        "### Obtain Tone Color Embedding\n",
        "We only extract the tone color embedding for the target speaker. The source tone color embeddings can be directly loaded from `checkpoints_v2/ses` folder."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option 1: Default reference speaker"
      ],
      "metadata": {
        "id": "dlfmFZv5P6kX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l50EZGCsBmrs"
      },
      "outputs": [],
      "source": [
        "reference_speaker = 'resources/example_reference.mp3' # This is the voice you want to clone\n",
        "target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, vad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option 2: Pick a voice from voice samples"
      ],
      "metadata": {
        "id": "meH_BNrSQywN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "voice_samples_dir = \"/content/voice_samples-master/voice_samples\"\n",
        "voice_files = sorted([f for f in os.listdir(voice_samples_dir) if os.path.isfile(os.path.join(voice_samples_dir, f))])\n",
        "\n",
        "# Create the dropdown menu using ipywidgets\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=[\"None\"] + voice_files,\n",
        "    value=\"None\",\n",
        "    description='Select voice file:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "display(dropdown)"
      ],
      "metadata": {
        "id": "KefdaCGWQ16G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference_speaker = f\"/content/voice_samples-master/voice_samples/{dropdown.value}\"\n",
        "print(f\"Selected voice file: {reference_speaker}\")\n",
        "target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, target_dir='processed', vad=True)"
      ],
      "metadata": {
        "id": "gIX138EsRBH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(reference_speaker)"
      ],
      "metadata": {
        "id": "HydogFwQREFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option 3: Use your own voice"
      ],
      "metadata": {
        "id": "uGLjk9RuRGqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "from IPython.display import display, HTML, Javascript\n",
        "from base64 import b64decode\n",
        "\n",
        "sample_text = \"\"\"\n",
        "The year I began to say vahz instead of vase, a man I barely\n",
        "knew nearly accidentally killed me.\n",
        "\n",
        "The man was not hurt when the other car hit ours. The man I\n",
        "had known for one week held me in the street in a way that\n",
        "meant I couldn’t see my legs. I remember knowing that I shouldn’t\n",
        "look, and knowing that I would look if it wasn’t that I couldn’t.\n",
        "\n",
        "My blood was on the front of this man’s clothes.\n",
        "\n",
        "He said, “You’ll be okay, but this sweater is ruined.”\n",
        "\n",
        "I screamed from the fear of pain. But I did not feel any pain. In\n",
        "the hospital, after injections, I knew there was pain in the room —“\n",
        "I just didn’t know whose pain it was.\n",
        "\n",
        "What happened to one of my legs required four hundred stitches,\n",
        "which, when I told it, became five hundred stitches, because nothing\n",
        "is ever quite as bad as it could be.\n",
        "\n",
        "The five days they didn’t know if they could save my leg or not I\n",
        "stretched to ten.\n",
        "\"\"\"\n",
        "print(sample_text)\n",
        "\n",
        "# Register the save function to receive audio data from JS\n",
        "def save_audio(data, filename=\"/content/myvoice.wav\"):\n",
        "    audio_data = b64decode(data)\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(audio_data)\n",
        "    print(f\"Audio saved as {filename}\")\n",
        "\n",
        "output.register_callback('notebook.save_audio', save_audio)\n",
        "\n",
        "# Display recording controls in Colab\n",
        "display(HTML('''\n",
        "  <div>\n",
        "    <button id=\"start-record\">Start Recording</button>\n",
        "    <button id=\"stop-record\" disabled>Stop Recording</button>\n",
        "  </div>\n",
        "'''))\n",
        "\n",
        "display(Javascript('''\n",
        "let mediaRecorder;\n",
        "let audioChunks;\n",
        "\n",
        "document.getElementById(\"start-record\").onclick = async () => {\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "  mediaRecorder = new MediaRecorder(stream);\n",
        "  audioChunks = [];\n",
        "\n",
        "  mediaRecorder.ondataavailable = event => {\n",
        "    if (event.data.size > 0) {\n",
        "      audioChunks.push(event.data);\n",
        "    }\n",
        "  };\n",
        "\n",
        "  mediaRecorder.onstop = async () => {\n",
        "    const audioBlob = new Blob(audioChunks);\n",
        "    const reader = new FileReader();\n",
        "    reader.readAsDataURL(audioBlob);\n",
        "    reader.onloadend = () => {\n",
        "      const base64data = reader.result.split(',')[1];\n",
        "      google.colab.kernel.invokeFunction('notebook.save_audio', [base64data], {});\n",
        "    };\n",
        "  };\n",
        "\n",
        "  mediaRecorder.start();\n",
        "  document.getElementById(\"start-record\").disabled = true;\n",
        "  document.getElementById(\"stop-record\").disabled = false;\n",
        "};\n",
        "\n",
        "document.getElementById(\"stop-record\").onclick = () => {\n",
        "  mediaRecorder.stop();\n",
        "  document.getElementById(\"start-record\").disabled = false;\n",
        "  document.getElementById(\"stop-record\").disabled = true;\n",
        "};\n",
        "'''))\n"
      ],
      "metadata": {
        "id": "trEkGfn8RJz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to proper wav format using ffmpeg\n",
        "!ffmpeg -y -i /content/myvoice.wav -acodec pcm_s16le -ar 44100 /content/myvoice_fixed.wav && mv /content/myvoice_fixed.wav /content/myvoice.wav"
      ],
      "metadata": {
        "id": "ek5sOkhORQDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference_speaker = \"/content/myvoice.wav\"\n",
        "print(f\"Selected voice file: {reference_speaker}\")\n",
        "target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, target_dir='processed', vad=True)"
      ],
      "metadata": {
        "id": "8OjsoBlRRSlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(reference_speaker)"
      ],
      "metadata": {
        "id": "-zEN8h0PRVaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA_GYf2NBmrw"
      },
      "source": [
        "#### Use MeloTTS as Base Speakers\n",
        "\n",
        "MeloTTS is a high-quality multi-lingual text-to-speech library by @MyShell.ai, supporting languages including English (American, British, Indian, Australian, Default), Spanish, French, Chinese, Japanese, Korean. In the following example, we will use the models in MeloTTS as the base speakers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /usr/local/lib/python3.11/dist-packages/unidic_lite/dicdir /usr/local/lib/python3.11/dist-packages/unidic/dicdir"
      ],
      "metadata": {
        "id": "B2hL8Ag8J0jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z79IopJ7Bmry"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf {output_dir}/*"
      ],
      "metadata": {
        "id": "Xx_6pXn5KFKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phlMarU1Bmr0"
      },
      "outputs": [],
      "source": [
        "from melo.api import TTS\n",
        "\n",
        "texts = {\n",
        "    'EN_NEWEST': \"Did you ever hear a folk tale about a giant turtle?\",  # The newest English base speaker model\n",
        "    'EN': \"Did you ever hear a folk tale about a giant turtle?\",\n",
        "    'ES': \"El resplandor del sol acaricia las olas, pintando el cielo con una paleta deslumbrante.\",\n",
        "    'FR': \"La lueur dorée du soleil caresse les vagues, peignant le ciel d'une palette éblouissante.\",\n",
        "    'ZH': \"在这次vacation中，我们计划去Paris欣赏埃菲尔铁塔和卢浮宫的美景。\",\n",
        "    'JP': \"彼は毎朝ジョギングをして体を健康に保っています。\",\n",
        "    'KR': \"안녕하세요! 오늘은 날씨가 정말 좋네요.\",\n",
        "}\n",
        "\n",
        "\n",
        "src_path = f'{output_dir}/tmp.wav'\n",
        "\n",
        "# Speed is adjustable\n",
        "speed = 1.0\n",
        "\n",
        "output_files = []\n",
        "\n",
        "for language, text in texts.items():\n",
        "    model = TTS(language=language, device=device)\n",
        "    speaker_ids = model.hps.data.spk2id\n",
        "\n",
        "    for speaker_key in speaker_ids.keys():\n",
        "        speaker_id = speaker_ids[speaker_key]\n",
        "        speaker_key = speaker_key.lower().replace('_', '-')\n",
        "\n",
        "        source_se = torch.load(f'checkpoints_v2/base_speakers/ses/{speaker_key}.pth', map_location=device)\n",
        "        if torch.backends.mps.is_available() and device == 'cpu':\n",
        "            torch.backends.mps.is_available = lambda: False\n",
        "        model.tts_to_file(text, speaker_id, src_path, speed=speed)\n",
        "        save_path = f'{output_dir}/output_v2_{speaker_key}.wav'\n",
        "\n",
        "        output_files.append(save_path)\n",
        "\n",
        "        # Run the tone color converter\n",
        "        encode_message = \"@MyShell\"\n",
        "        tone_color_converter.convert(\n",
        "            audio_src_path=src_path,\n",
        "            src_se=source_se,\n",
        "            tgt_se=target_se,\n",
        "            output_path=save_path,\n",
        "            message=encode_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOjYD8IxBmr2"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgMRF6p5Bmr4"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD2BK6MOBmr5"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsxEbiS9Bmr7"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqfd727mBmr8"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t-5w4OVBmr8"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpS2OLkyBmr9"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQg3ggkTBmr-"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke6Xs4kNBmr-"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGkljzI_Bmr_"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgqfkZDvBmr_"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-uKQFiQBmsA"
      },
      "outputs": [],
      "source": [
        "Audio(output_files[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxBE9rsbBmsB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "openvoice",
      "language": "python",
      "name": "condaenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}