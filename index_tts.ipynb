{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1atTAVvwtQp"
      },
      "outputs": [],
      "source": [
        "!apt update && apt install ssh screen htop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/ && wget https://github.com/index-tts/index-tts/archive/refs/heads/main.zip && unzip main.zip && rm -rf main.zip"
      ],
      "metadata": {
        "id": "Ffp-Kt4WxlsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg"
      ],
      "metadata": {
        "id": "IBpUKazTxupQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd index-tts-main && pip install -e . --no-build-isolation"
      ],
      "metadata": {
        "id": "WFztyrSfx6kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lBWoqF1KMiFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart session"
      ],
      "metadata": {
        "id": "wwZlNUMY0Gsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepspeed"
      ],
      "metadata": {
        "id": "Sj0IuSBW4GDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd index-tts-main/ && huggingface-cli download IndexTeam/IndexTTS-1.5 \\\n",
        "  config.yaml bigvgan_discriminator.pth bigvgan_generator.pth bpe.model dvae.pth gpt.pth unigram_12000.vocab \\\n",
        "  --local-dir checkpoints"
      ],
      "metadata": {
        "id": "8L14zP6Kzb-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"/content/index-tts-main/output.wav\""
      ],
      "metadata": {
        "id": "WyRMfcjw0rB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(\"/content/index-tts-main/fiona_zh.mp3\")"
      ],
      "metadata": {
        "id": "SplgvGESLvDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tn"
      ],
      "metadata": {
        "id": "Czl1v-b6PVJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from indextts.infer import IndexTTS\n",
        "tts = IndexTTS(model_dir=\"/content/index-tts-main/checkpoints\",cfg_path=\"/content/index-tts-main/checkpoints/config.yaml\")\n",
        "voice=\"/content/index-tts-main/fiona_zh.mp3\"\n",
        "#text=\"大家好，我现在正在bilibili 体验 ai 科技，说实话，来之前我绝对想不到！AI技术已经发展到这样匪夷所思的地步了！比如说，现在正在说话的其实是B站为我现场复刻的数字分身，简直就是平行宇宙的另一个我了。如果大家也想体验更多深入的AIGC功能，可以访问 bilibili studio，相信我，你们也会吃惊的。\"\n",
        "\n",
        "text=\"President Donald Trump on Monday threatened Russia with steep tariffs and announced a rejuvenated pipeline for American weapons to reach Ukraine, hardening his stance toward Moscow after months of frustration about unsuccessful negotiations for ending the war.\"\n",
        "tts.infer(voice, text, output_path)"
      ],
      "metadata": {
        "id": "I3Z_KM0yz2pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(\"/content/index-tts-main/output.wav\")"
      ],
      "metadata": {
        "id": "aQEcOSHI0z7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Small Incident"
      ],
      "metadata": {
        "id": "qjYZrgiq1u9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 一件小事⑴\n",
        "# 鲁迅\n",
        "# From https://www.comp.nus.edu.sg/~tanhw/chinese/literature/lu-xun/yi-jian-xiao-shi.html?utm_source=chatgpt.com\n",
        "text_str = \"\"\"\n",
        "　　我从乡下跑到京城里，一转眼已经六年了。其间耳闻目睹的所谓国家大事\n",
        "，算起来也很不少；但在我心里，都不留什么痕迹，倘要我寻出这些事的影响\n",
        "来说，便只是增长了我的坏脾气，——老实说，便是教我一天比一天的看不起\n",
        "人。\n",
        "\n",
        "　　但有一件小事，却于我有意义，将我从坏脾气里拖开，使我至今忘记不得\n",
        "。\n",
        "\n",
        "　　这是民国六年的冬天，大北风刮得正猛，我因为生计关系，不得不一早在\n",
        "路上走。一路几乎遇不见人，好容易才雇定了一辆人力车，教他拉到Ｓ门去。\n",
        "不一会，北风小了，路上浮尘早已刮净，剩下一条洁白的大道来，车夫也跑得\n",
        "更快。刚近Ｓ门，忽而车把上带着一个人，慢慢地倒了。\n",
        "\n",
        "　　跌倒的是一个女人，花白头发，衣服都很破烂。伊从马路上突然向车前横\n",
        "截过来；车夫已经让开道，但伊的破棉背心没有上扣，微风吹着，向外展开，\n",
        "所以终于兜着车把。幸而车夫早有点停步，否则伊定要栽一个大斤斗，跌到头\n",
        "破血出了。\n",
        "\n",
        "　　伊伏在地上；车夫便也立住脚。我料定这老女人并没有伤，又没有别人看\n",
        "见，便很怪他多事，要自己惹出是非，也误了我的路。\n",
        "\n",
        "　　我便对他说，“没有什么的。走你的罢！”\n",
        "\n",
        "　　车夫毫不理会，——或者并没有听到，——却放下车子，扶那老女人慢慢\n",
        "起来，搀着臂膊立定，问伊说：\n",
        "\n",
        "　　“你怎么啦？”\n",
        "\n",
        "　　“我摔坏了。”\n",
        "\n",
        "　　我想，我眼见你慢慢倒地，怎么会摔坏呢，装腔作势罢了，这真可憎恶。\n",
        "车夫多事，也正是自讨苦吃，现在你自己想法去。\n",
        "\n",
        "　　车夫听了这老女人的话，却毫不踌躇，仍然搀着伊的臂膊，便一步一步的\n",
        "向前走。我有些诧异，忙看前面，是一所巡警分驻所，大风之后，外面也不见\n",
        "人。这车夫扶着那老女人，便正是向那大门走去。\n",
        "\n",
        "　　我这时突然感到一种异样的感觉，觉得他满身灰尘的后影，刹时高大了，\n",
        "而且愈走愈大，须仰视才见。而且他对于我，渐渐的又几乎变成一种威压，甚\n",
        "而至于要榨出皮袍下面藏着的“小”来。\n",
        "\n",
        "　　我的活力这时大约有些凝滞了，坐着没有动，也没有想，直到看见分驻所\n",
        "里走出一个巡警，才下了车。\n",
        "\n",
        "　　巡警走近我说，“你自己雇车罢，他不能拉你了。”\n",
        "\n",
        "　　我没有思索的从外套袋里抓出一大把铜元，交给巡警，说，“请你给他…\n",
        "…”\n",
        "\n",
        "　　风全住了，路上还很静。我走着，一面想，几乎怕敢想到自己。以前的事\n",
        "姑且搁起，这一大把铜元又是什么意思？奖他么？我还能裁判车夫么？我不能\n",
        "回答自己。\n",
        "\n",
        "　　这事到了现在，还是时时记起。我因此也时时煞了苦痛，努力的要想到我\n",
        "自己。几年来的文治武力，在我早如幼小时候所读过的“子曰诗云”⑵一般，\n",
        "背不上半句了。独有这一件小事，却总是浮在我眼前，有时反更分明，教我惭\n",
        "愧，催我自新，并且增长我的勇气和希望。\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1uYdq1Hy17Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def split_chinese_text_into_paragraphs_and_sentences(text):\n",
        "    \"\"\"\n",
        "    Splits Chinese text into paragraphs and then sentences within each paragraph.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input Chinese text.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of lists, where each inner list contains sentences from a paragraph.\n",
        "    \"\"\"\n",
        "    # Normalize full-width spaces and strip leading/trailing whitespace\n",
        "    text = text.replace('\\u3000', '').strip()\n",
        "\n",
        "    # Split into paragraphs by two or more newlines\n",
        "    paragraphs = re.split(r'\\n\\s*\\n', text)\n",
        "\n",
        "    paragraph_sentences = []\n",
        "    for paragraph in paragraphs:\n",
        "        # Remove excess internal newlines within paragraphs\n",
        "        paragraph = paragraph.replace('\\n', '')\n",
        "        # Split into sentences by Chinese punctuation (keep the punctuation)\n",
        "        sentences = re.split(r'(?<=[。！？])', paragraph)\n",
        "        # Remove empty strings and strip whitespace\n",
        "        sentences = [s.strip() for s in sentences if s.strip()]\n",
        "        paragraph_sentences.append(sentences)\n",
        "\n",
        "    return paragraph_sentences\n",
        "\n",
        "# Example usage:\n",
        "sentences_by_paragraph = split_chinese_text_into_paragraphs_and_sentences(text_str)\n",
        "\n",
        "# Display the results\n",
        "for i, paragraph in enumerate(sentences_by_paragraph):\n",
        "    print(f\"Paragraph {i+1}:\")\n",
        "    for j, sentence in enumerate(paragraph):\n",
        "        print(f\"  Sentence {j+1}: {sentence}\")\n",
        "    print(\"-\" * 20)\n"
      ],
      "metadata": {
        "id": "32feCLnD13a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from indextts.infer import IndexTTS\n",
        "tts = IndexTTS(model_dir=\"/content/index-tts-main/checkpoints\",cfg_path=\"/content/index-tts-main/checkpoints/config.yaml\")\n",
        "voice=\"/content/index-tts-main/fiona_zh.mp3\"\n",
        "\n",
        "def generate_audio(save_path, text, tts, voice):\n",
        "    tts.infer(voice, text, save_path)"
      ],
      "metadata": {
        "id": "Xfsq4MNX2CVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torchaudio as ta\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Create directory for sentence wav files\n",
        "output_dir = \"sentences\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Synthesize each sentence and save to a file\n",
        "sentence_files = []\n",
        "sentence_count = 0\n",
        "for paragraph_index, paragraph_sentences in enumerate(sentences_by_paragraph):\n",
        "    for sentence_index, sentence in enumerate(paragraph_sentences):\n",
        "        # Ensure sentence is not empty after splitting\n",
        "        if sentence.strip():\n",
        "            sentence_count += 1\n",
        "            print(f\"Synthesizing sentence {sentence_count}: {sentence}\")\n",
        "            sentence = sentence.strip()\n",
        "\n",
        "            file_path = os.path.join(output_dir, f\"sentence_{sentence_count}.wav\")\n",
        "\n",
        "            generate_audio(file_path, sentence, tts, voice)\n",
        "\n",
        "            sentence_files.append(file_path)\n",
        "\n",
        "# Merge all sentence wav files\n",
        "merged_audio = None\n",
        "pause_duration_ms = 500  # Adjust the pause duration as needed (in milliseconds)\n",
        "paragraph_end_pause_ms = 1000 # Pause duration after each paragraph\n",
        "\n",
        "file_index = 0\n",
        "sentence_counter_for_paragraph = 0\n",
        "\n",
        "for paragraph_index, paragraph_sentences in enumerate(sentences_by_paragraph):\n",
        "    sentence_counter_for_paragraph = 0\n",
        "    for sentence_index, sentence in enumerate(paragraph_sentences):\n",
        "        if sentence.strip():\n",
        "            file_path = sentence_files[file_index]\n",
        "            audio_segment = AudioSegment.from_wav(file_path)\n",
        "\n",
        "            if merged_audio is None:\n",
        "                merged_audio = audio_segment\n",
        "            else:\n",
        "                merged_audio += audio_segment\n",
        "\n",
        "            file_index += 1\n",
        "            sentence_counter_for_paragraph += 1\n",
        "\n",
        "    # Add a pause after each paragraph (if it's not the last paragraph)\n",
        "    if paragraph_index < len(sentences_by_paragraph) - 1:\n",
        "         # Add a pause at the end of the paragraph\n",
        "         pause = AudioSegment.silent(duration=paragraph_end_pause_ms)\n",
        "         if merged_audio is not None:\n",
        "            merged_audio += pause\n",
        "\n",
        "\n",
        "# Save the final merged audio\n",
        "if merged_audio is not None:\n",
        "    output_filename = \"A_Small_Incident.wav\"\n",
        "    merged_audio.export(output_filename, format=\"wav\")\n",
        "    print(f\"Merged audio saved as {output_filename}\")"
      ],
      "metadata": {
        "id": "Bn40jK_52hv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video\n",
        "Video(\"A_Small_Incident.wav\", embed=True)"
      ],
      "metadata": {
        "id": "zfSWiUre6BZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate video"
      ],
      "metadata": {
        "id": "QYoRST_v8sHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install fonts-noto-cjk"
      ],
      "metadata": {
        "id": "gD2OD4R897l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fc-list | grep \"Noto Sans CJK\""
      ],
      "metadata": {
        "id": "b4opEZ5S-BpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Get duration in seconds (as float)\n",
        "result = subprocess.run(\n",
        "    [\"ffprobe\", \"-i\", \"A_Small_Incident.wav\", \"-show_entries\", \"format=duration\", \"-v\", \"quiet\", \"-of\", \"csv=p=0\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "duration = float(result.stdout.strip())\n",
        "print(\"Duration:\", duration)"
      ],
      "metadata": {
        "id": "3EXVTeJ-8rgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to integer seconds if desired\n",
        "duration_sec = int(duration)\n",
        "\n",
        "!ffmpeg -y -f lavfi -i color=c=black:s=640x480:d={duration_sec} \\\n",
        "-i A_Small_Incident.wav \\\n",
        "-vf \"drawtext=fontfile=/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc:text='一件小事':fontsize=40:fontcolor=white:x=(w-text_w)/2:y=h/2-30,\\\n",
        "drawtext=fontfile=/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc:text='鲁迅':fontsize=40:fontcolor=white:x=(w-text_w)/2:y=h/2+30\" \\\n",
        "-c:v libx264 -c:a aac -shortest A_Small_Incident__index_tts.mp4"
      ],
      "metadata": {
        "id": "mpKr5m-580PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video\n",
        "Video(\"A_Small_Incident__index_tts.mp4\", embed=True)"
      ],
      "metadata": {
        "id": "sd8KWbvW9Oup"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}